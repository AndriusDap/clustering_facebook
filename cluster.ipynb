{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Squared Error = 3936.395819990664\n",
      "data/0: 5\n",
      "Sum of Squared Error = 31820.593260163827\n",
      "data/1684: 2\n",
      "Sum of Squared Error = 12812.2665933378\n",
      "data/3437: 1\n",
      "Sum of Squared Error = 24568.987716255542\n",
      "data/1912: 7\n",
      "Sum of Squared Error = 988.9528871469414\n",
      "data/686: 2\n",
      "Sum of Squared Error = 303.90428695811994\n",
      "data/698: 1\n",
      "Sum of Squared Error = 40870.10842838598\n",
      "data/107: 5\n",
      "Sum of Squared Error = 1705.4322462820162\n",
      "data/414: 3\n",
      "Sum of Squared Error = 163.46499397250656\n",
      "data/3980: 1\n",
      "Sum of Squared Error = 2250.6126863962145\n",
      "data/348: 4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.clustering import KMeans\n",
    "from pyspark.mllib.clustering import GaussianMixture\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "from pyspark import SparkContext\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pyspark\n",
    "import glob\n",
    "\n",
    "\n",
    "selectedFile = \"data/3980\" \n",
    "for selectedFile in glob.glob(\"data/*.feat\"):\n",
    "    selectedFile = selectedFile.split(\".\")[0]\n",
    "    file = selectedFile + \".feat\"\n",
    "    egofile = selectedFile + \".egofeat\"\n",
    "\n",
    "    data = sc.textFile(file)\n",
    "    parsedData = data.map(lambda line: array([float(x) for x in line.split(' ')]))\n",
    "\n",
    "    model = KMeans.train(parsedData, 8, maxIterations=20, runs=30,  initializationMode=\"k-means||\")\n",
    "\n",
    "    vecAssembler = VectorAssembler(inputCols=[], outputCol=\"features\")\n",
    "    scaler = StandardScaler(withMean=True, withStd=True, inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "    firstPipeline = Pipeline(stages=[vecAssembler, model])\n",
    "\n",
    "    centroids = model.centers\n",
    "    weights = model.k\n",
    "    cost = model.computeCost(parsedData)\n",
    "\n",
    "    def error(point):\n",
    "        center = model.centers[model.predict(point)]\n",
    "        return sqrt(sum([x**2 for x in (point - center)]))\n",
    "\n",
    "    WSSSE = parsedData.map(lambda point: error(point)).reduce(lambda x, y: x + y)\n",
    "    print(\"Sum of Squared Error = \" + str(WSSSE))    \n",
    "\n",
    "    egodata = sc.textFile(egofile)\n",
    "    egoparsedData = egodata.map(lambda line: array([0] + [float(x) for x in line.split(' ')]))\n",
    "    print(selectedFile + \": \"+ str(model.predict(egoparsedData).collect()[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-acedb832a8b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mall_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsedData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mdraw_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[0mcluster_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_clusters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-acedb832a8b1>\u001b[0m in \u001b[0;36mdraw_graph\u001b[1;34m(graph, clusters)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdraw_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mG\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-acedb832a8b1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdraw_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mG\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import colorsys\n",
    "import matplotlib.pylab as pylab\n",
    "import glob\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = 12, 12  \n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#' + ''.join(['%02x' % int(p * 255) for p in rgb])\n",
    "\n",
    "def get_colours(count):\n",
    "    count = count + 1\n",
    "    colours = [colorsys.hsv_to_rgb(h / count, 1, 1) for h in range(count)]\n",
    "    return [rgb_to_hex(c) for c in colours]\n",
    "\n",
    "def draw_graph(graph, clusters):\n",
    "    nodes = set([n1 for n1, n2 in graph] + [n2 for n1, n2 in graph])\n",
    "    G=nx.Graph()\n",
    "    for node in nodes:\n",
    "        G.add_node(node)\n",
    "    for edge in graph:\n",
    "        G.add_edge(edge[0], edge[1])\n",
    "    pos = nx.spring_layout(G, k=0.04, iterations=10)\n",
    "    \n",
    "    rainbow = get_colours(max(clusters))\n",
    "    colours = ['r' for n in G.nodes()]\n",
    "    for i in range(len(G.nodes())):\n",
    "        colours[i] = rainbow[clusters[i]]\n",
    "        \n",
    "    nx.draw_networkx(G,\n",
    "                     pos,\n",
    "                     node_size=100,\n",
    "                     linewidths=0.5,\n",
    "                     with_labels=False,\n",
    "                     node_color=colours) \n",
    "    \n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def read_file(name):\n",
    "    with open(name, \"r\") as f:\n",
    "        return[list(map(int, line.split())) for line in f.readlines()]\n",
    "\n",
    "\n",
    "all_clusters = model.predict(parsedData).collect() \n",
    "draw_graph(read_file(file), all_clusters) \n",
    "cluster_counts = {}\n",
    "for a in all_clusters:\n",
    "    if a in cluster_counts:\n",
    "        cluster_counts[a] = cluster_counts[a] + 1\n",
    "    else:\n",
    "        cluster_counts[a] = 1\n",
    "print(cluster_counts) \n",
    "\n",
    "\n",
    "egodata = sc.textFile(egofile)\n",
    "egoparsedData = egodata.map(lambda line: array([0] + [float(x) for x in line.split(' ')]))\n",
    "print(model.predict(egoparsedData).collect())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark 1.5.1 (Python 3.4)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
