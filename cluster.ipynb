{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import KMeans\n",
    "from pyspark.mllib.clustering import GaussianMixture\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "from pyspark import SparkContext\n",
    "from numpy import array\n",
    "from math import sqrt\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pyspark\n",
    "\n",
    "\n",
    "file = \"data/0.feat\"\n",
    "\n",
    "data = sc.textFile(file)\n",
    "parsedData = data.map(lambda line: array([float(x) for x in line.split(' ')]))\n",
    "\n",
    "clusters = KMeans.train(parsedData, 6, maxIterations=20, runs=30,  initializationMode=\"k-means||\")\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=[], outputCol=\"features\")\n",
    "scaler = StandardScaler(withMean=True, withStd=True, inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "firstPipeline = Pipeline(stages=[vecAssembler, clusters])\n",
    "\n",
    "centroids = clusters.centers\n",
    "weights = clusters.k\n",
    "cost = clusters.computeCost(parsedData)\n",
    "\n",
    "def error(point):\n",
    "    center = clusters.centers[clusters.predict(point)]\n",
    "    return sqrt(sum([x**2 for x in (point - center)]))\n",
    "\n",
    "WSSSE = parsedData.map(lambda point: error(point)).reduce(lambda x, y: x + y)\n",
    "print(\"Within Set Sum of Squared Error = \" + str(WSSSE))\n",
    "\n",
    "gmm = GaussianMixture.train(parsedData, 2)\n",
    "for i in range(2):\n",
    "    print (\"weight = \", gmm.weights[i], \"mu = \", gmm.gaussians[i].mu,\n",
    "        \"sigma = \", gmm.gaussians[i].sigma.toArray())\n",
    "    \n",
    "    \n",
    "#corpus = parsedDataForLDA.zipWithIndex().map(lambda x: [x[1], x[0]]).cache()\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import ggplot as gg\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import colorsys\n",
    "import matplotlib.pylab as pylab\n",
    "import glob\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = 12, 12  \n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#' + ''.join(['%02x' % int(p * 255) for p in rgb])\n",
    "\n",
    "def get_colours(count):\n",
    "    count = count + 1\n",
    "    colours = [colorsys.hsv_to_rgb(h / count, 1, 1) for h in range(count)]\n",
    "    return [rgb_to_hex(c) for c in colours]\n",
    "\n",
    "def draw_graph(graph):\n",
    "    nodes = set([n1 for n1, n2 in graph] + [n2 for n1, n2 in graph])\n",
    "    G=nx.Graph()\n",
    "    for node in nodes:\n",
    "        G.add_node(node)\n",
    "    for edge in graph:\n",
    "        G.add_edge(edge[0], edge[1])\n",
    "    pos = nx.spring_layout(G, k=0.25)\n",
    "    \n",
    "    c = list(nx.k_clique_communities(G, 10))\n",
    "    rainbow = get_colours(len(c))\n",
    "    colours = ['r' for n in G.nodes()]\n",
    "    for node in G.nodes():\n",
    "        colours[G.nodes().index(node)] = rainbow[len(c)]\n",
    "        for community in c:\n",
    "            if node in community:\n",
    "                colours[G.nodes().index(node)] = rainbow[c.index(community)]\n",
    "    \n",
    "    nx.draw_networkx(G,\n",
    "                     pos,\n",
    "                     node_size=100,\n",
    "                     linewidths=0.5,\n",
    "                     with_labels=False,\n",
    "                     node_color=colours) \n",
    "    \n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def read_file(name):\n",
    "    with open(name, \"r\") as f:\n",
    "        return[list(map(int, line.split())) for line in f.readlines()]\n",
    "    \n",
    "\n",
    "graph = [(20, 21),(21, 22),(22, 23), (23, 24),(24, 25), (25, 20)]\n",
    "draw_graph(graph)\n",
    "#draw_graph(read_file(\"data/0.edges\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark 1.5.1 (Python 3.4)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
